# LLM_learner
Learning how to use, fine-tune and build with LLMs

## Resources
### LLMs
- [[1hr Talk] Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g)
- [A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU)

### Fine-Tuning
- [Finetuning open-source LLMs](https://www.youtube.com/watch?v=gs-IDg-FoIQ)https://www.youtube.com/watch?v=gs-IDg-FoIQ
- [How to fine-tune Mistral 7b on your data](https://www.youtube.com/watch?v=kmkcNVvEz-k)https://www.youtube.com/watch?v=kmkcNVvEz-k
- [Fine-Tuning your own Llama2](https://www.youtube.com/watch?v=Pb_RGAl75VE&t=14s)https://www.youtube.com/watch?v=Pb_RGAl75VE&t=14s
- [Webinar: How to Fine-Tune LLMs with QLoRA](https://www.youtube.com/watch?v=9Ieaf42tOnw)
- [Fine-tuning Large Language Models (LLMs) | w/ Example Code](https://www.youtube.com/watch?v=eC6Hd1hFvos)

### Lora
- [What is LoRA? Low-Rank Adaptation for finetuning LLMs EXPLAINED](https://www.youtube.com/watch?v=KEv-F5UkhxU)https://www.youtube.com/watch?v=KEv-F5UkhxU
- [Low-rank Adaptation: LoRA Fine-tuning & QLoRA Explained In-Depth](https://www.youtube.com/watch?v=t1caDsMzWBk&pp=ygUObG9yYSBhbmQgcWxvcmE%3D)https://www.youtube.com/watch?v=t1caDsMzWBk&pp=ygUObG9yYSBhbmQgcWxvcmE%3D
- [LoRA explained (and a bit about precision and quantization)](https://www.youtube.com/watch?v=t509sv5MT0w&t=18s&pp=ygUObG9yYSBhbmQgcWxvcmE%3D)https://www.youtube.com/watch?v=t509sv5MT0w&t=18s&pp=ygUObG9yYSBhbmQgcWxvcmE%3D
- [Fine-Tune Large LLMs with QLoRA (Free Colab Tutorial)](https://www.youtube.com/watch?v=NRVaRXDoI3g)https://www.youtube.com/watch?v=NRVaRXDoI3g

### Quantization
- [Understanding 4bit Quantization: QLoRA explained (w/ Colab)](https://www.youtube.com/watch?v=TPcXVJ1VSRI)https://www.youtube.com/watch?v=TPcXVJ1VSRI
- [Understanding: AI Model Quantization, GGML vs GPTQ!](https://www.youtube.com/watch?v=ZKdMbQq5T30)
- [AWQ for LLM Quantization](https://www.youtube.com/watch?v=3dYLj9vjfA0)
- [How to Quantize an LLM with GGUF or AWQ](https://www.youtube.com/watch?v=XM8pllpBVA0)
- [New Tutorial on LLM Quantization w/ QLoRA, GPTQ and Llamacpp, LLama 2](https://www.youtube.com/watch?v=YEVyupJxt1Q)

### PEFT
- [PEFT LoRA Explained in Detail - Fine-Tune your LLM on your local GPU](https://www.youtube.com/watch?v=YVU5wAA6Txo)https://www.youtube.com/watch?v=YVU5wAA6Txo
- [Fine-tuning LLMs with PEFT and LoRA](https://www.youtube.com/watch?v=Us5ZFp16PaU)https://www.youtube.com/watch?v=Us5ZFp16PaU
- [Efficient Large Language Model training with LoRA and Hugging Face PEFT](https://www.youtube.com/watch?v=YKCtbIJC3kQ)https://www.youtube.com/watch?v=YKCtbIJC3kQ
- [EMNLP 2022 Tutorial - "Modular and Parameter-Efficient Fine-Tuning for NLP Models"](https://www.youtube.com/watch?v=KoOlcX3XLd4)https://www.youtube.com/watch?v=KoOlcX3XLd4

### DDPO / TRL
- [Finetune Stable Diffusion Models with DDPO via TRL](https://huggingface.co/blog/trl-ddpo)https://huggingface.co/blog/trl-ddpo
- [Non-engineers guide: Train a LLaMA 2 chatbot](https://huggingface.co/blog/Llama2-for-non-engineers)https://huggingface.co/blog/Llama2-for-non-engineers